{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import imp\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3919,  1.3056,  2.7853,  ...,  0.5766, -0.0803,  0.1211],\n",
       "         [-0.8576,  0.3325, -1.5713,  ...,  0.8298,  1.4680,  0.2883],\n",
       "         [ 0.3307, -0.0675, -0.0202,  ..., -1.8999, -0.4316,  1.4966]],\n",
       "\n",
       "        [[-0.3773,  0.4957, -0.0476,  ..., -0.2832, -0.1372, -1.4229],\n",
       "         [-1.2645,  1.4329,  0.2567,  ...,  1.3165,  1.5666, -0.7734],\n",
       "         [-1.0333, -0.3981,  0.5251,  ...,  0.7937, -3.1634, -1.6036]],\n",
       "\n",
       "        [[ 0.4099,  1.3257, -0.5460,  ...,  0.1601, -1.0242,  3.4976],\n",
       "         [-0.2699,  0.1462,  0.5616,  ..., -0.4750,  1.5428,  0.5463],\n",
       "         [ 0.1554,  0.1756,  0.4237,  ...,  1.4789,  0.8346,  1.7382]],\n",
       "\n",
       "        [[-0.4651, -1.5848, -0.8459,  ...,  0.9008, -0.4355, -0.7192],\n",
       "         [ 0.7424,  1.6123,  0.1406,  ...,  1.6709,  1.8635, -0.9863],\n",
       "         [ 0.4178,  0.8939, -0.4980,  ..., -0.0662, -1.0376,  0.6484]],\n",
       "\n",
       "        [[ 1.3107, -1.9186, -0.2184,  ...,  2.4746, -0.3871,  0.6651],\n",
       "         [-1.0621, -0.1679, -0.3245,  ...,  0.8142, -0.2886, -1.1276],\n",
       "         [-1.3026,  1.3236, -1.0031,  ..., -0.5547,  0.7717, -1.0161]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(model)\n",
    "t_encoder = model.TransformerEncoder(512, 2048, 8)\n",
    "garbo = torch.randn([5, 3, 512])\n",
    "t_encoder(garbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1340, -2.4886, -0.8158,  ..., -1.3069,  0.6582, -0.2000],\n",
       "         [ 0.9730,  0.6135,  1.3360,  ..., -0.6189,  0.7572, -0.2927],\n",
       "         [ 0.5044, -0.4754,  0.6966,  ..., -0.6785,  0.2270,  0.5809],\n",
       "         ...,\n",
       "         [ 0.4396, -0.6911,  1.0307,  ..., -0.9800,  0.4814,  0.5603],\n",
       "         [ 1.0428, -0.4181, -1.0202,  ...,  0.0303, -0.1106, -0.8201],\n",
       "         [ 1.0106, -0.0851, -1.8520,  ...,  0.4411,  1.6800,  1.0390]],\n",
       "\n",
       "        [[ 1.0493,  0.5924,  0.4759,  ..., -1.3204, -0.8716, -0.4978],\n",
       "         [ 0.0323, -0.5359, -0.4389,  ...,  0.6856, -2.5974, -1.0534],\n",
       "         [ 2.0715, -1.6705,  2.2953,  ...,  0.6928, -2.3826, -0.9096],\n",
       "         ...,\n",
       "         [-1.2594, -1.5195,  1.5254,  ..., -0.3101, -0.9397, -1.4128],\n",
       "         [-0.3019, -0.7243,  1.7135,  ..., -0.5253, -0.4199, -0.2297],\n",
       "         [-0.8845, -0.8706, -1.1603,  ..., -0.6155, -0.7455, -0.1628]],\n",
       "\n",
       "        [[-2.6066, -0.4953,  0.2677,  ...,  0.2017, -1.5251,  0.2368],\n",
       "         [-0.8730,  1.8175,  0.2143,  ...,  0.7573,  1.5686, -0.1004],\n",
       "         [-1.9293,  1.5206, -0.9719,  ...,  0.2294,  0.0329,  0.8797],\n",
       "         ...,\n",
       "         [ 0.4187,  0.0053, -0.1927,  ...,  0.2227, -0.6122,  1.6239],\n",
       "         [ 0.3579,  0.1218, -2.0114,  ...,  1.9529,  0.9160,  0.5977],\n",
       "         [-0.5860, -1.0412, -0.3143,  ...,  0.8726, -0.4895,  0.3287]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(model)\n",
    "t_decoder = model.TransformerDecoder(512, 2048, 8)\n",
    "latents = torch.randn([3, 24, 512])\n",
    "encoding = torch.randn([3, 12, 512])\n",
    "t_decoder(latents, encoding, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1361, 22.4500,  0.9968,  ..., 22.8534, -1.1935, 22.9010],\n",
       "         [18.7065, 11.6253, 18.9846,  ..., 21.8329, -1.1898, 21.8931],\n",
       "         [19.2721, -8.6487, 20.6473,  ..., 20.9235, -1.1703, 20.9710],\n",
       "         ...,\n",
       "         [ 2.1295, -1.2201,  2.4790,  ...,  2.1515, -0.9121,  2.4115],\n",
       "         [ 0.5267, -1.7430,  1.1913,  ...,  1.1668, -0.9808,  1.4291],\n",
       "         [ 0.5845, -0.6845,  0.5750,  ...,  0.2737, -1.0405,  0.3730]],\n",
       "\n",
       "        [[-0.0839, 22.7824,  0.4814,  ..., 22.6989, -0.7440, 23.0256],\n",
       "         [18.5290, 11.9640, 18.4956,  ..., 21.6499, -0.7296, 21.9924],\n",
       "         [19.0662, -8.2994, 20.1651,  ..., 20.7429, -0.6760, 21.0704],\n",
       "         ...,\n",
       "         [ 1.9713, -0.8444,  1.9705,  ...,  1.9879, -0.4902,  2.5494],\n",
       "         [ 0.3454, -1.3538,  0.6243,  ...,  1.0128, -0.5615,  1.5962],\n",
       "         [ 0.3863, -0.2940,  0.0240,  ...,  0.1477, -0.6127,  0.5070]],\n",
       "\n",
       "        [[ 0.0536, 22.6742,  0.5680,  ..., 22.5452, -1.1038, 23.3907],\n",
       "         [18.6602, 11.8459, 18.5677,  ..., 21.5317, -1.0856, 22.4186],\n",
       "         [19.2019, -8.4339, 20.2555,  ..., 20.5757, -1.0432, 21.4766],\n",
       "         ...,\n",
       "         [ 2.0531, -0.9772,  2.0149,  ...,  1.8596, -0.8163,  2.9145],\n",
       "         [ 0.4640, -1.4992,  0.6983,  ...,  0.8615, -0.9284,  2.0171],\n",
       "         [ 0.4824, -0.4074,  0.0565,  ..., -0.0524, -1.0088,  0.9368]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(model)\n",
    "transformer = model.Transformer(dims=512, ff_width=2048, heads=4, encode_blocks=6, seq_len=12, out_seq_len=24)\n",
    "garbo = torch.randn([3, 12, 512])\n",
    "transformer(garbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 1, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(model)\n",
    "imEncoder = model.ImageEncoder([1, 16, 32, 64, 128, 256, 512], kernel_size=3, stride=2)\n",
    "garbo = torch.randn([3, 128, 128])\n",
    "imEncoder(garbo).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 64, 64])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(model)\n",
    "attConv = model.AttentionConv()\n",
    "garbo = torch.randn([1, 12, 128, 128])\n",
    "attConv(garbo).shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bba7e75823fc7474598fdaa9856f2217ab6bebf37b5fa259dabfeda760a6edd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

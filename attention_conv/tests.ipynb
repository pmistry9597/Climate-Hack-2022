{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30592/1004799806.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Climate-Hack-2022/attention_conv/ae.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageDecoder128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import imp\n",
    "import model\n",
    "import ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0593, -0.2840,  0.1293,  ..., -0.1548,  0.2912,  1.3441],\n",
       "         [-0.5819,  1.1006,  0.1826,  ..., -1.4124, -0.0634,  1.4136],\n",
       "         [-1.8536, -2.8996,  0.8806,  ...,  1.0322,  1.2258,  0.1068]],\n",
       "\n",
       "        [[ 0.2850,  0.2532, -0.3758,  ...,  0.6471,  1.3181,  0.5549],\n",
       "         [-0.0725, -0.7545,  0.3325,  ...,  1.7533, -1.0622,  0.5387],\n",
       "         [-0.4718, -0.3572, -0.0613,  ...,  0.8440,  0.5968, -1.6120]],\n",
       "\n",
       "        [[-1.1855, -1.5337, -0.3962,  ..., -0.8115, -0.0097, -1.9258],\n",
       "         [ 0.8307,  1.6460,  0.5789,  ..., -1.6798, -1.1845,  2.4132],\n",
       "         [-0.2101, -2.0987, -0.1556,  ...,  1.0563,  0.5378, -0.6632]],\n",
       "\n",
       "        [[ 1.3859, -1.3077,  1.2102,  ...,  0.3974, -0.1574,  1.3628],\n",
       "         [ 1.0432,  0.9412, -0.8101,  ...,  0.0168,  0.2070,  1.0236],\n",
       "         [-0.4724, -1.1031,  0.0410,  ...,  1.0558,  1.5716,  0.5177]],\n",
       "\n",
       "        [[-1.4900, -1.0805,  0.8262,  ..., -0.6927,  0.0453,  0.0875],\n",
       "         [-0.0531,  1.4309,  1.6724,  ..., -0.4478,  0.2782,  0.8331],\n",
       "         [-0.3183,  0.2572, -1.7532,  ...,  0.5507,  0.3201,  1.9318]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(model)\n",
    "t_encoder = model.TransformerEncoder(512, 2048, 8)\n",
    "garbo = torch.randn([5, 3, 512])\n",
    "t_encoder(garbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 24, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(model)\n",
    "t_decoder = model.TransformerDecoder(512, 2048, 8)\n",
    "latents = torch.randn([3, 24, 512])\n",
    "encoding = torch.randn([3, 12, 512])\n",
    "t_decoder(latents, encoding, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 24, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(model)\n",
    "transformer = model.Transformer(dims=512, ff_width=2048, heads=4, encode_blocks=6, seq_len=12, out_seq_len=24)\n",
    "garbo = torch.randn([3, 12, 512])\n",
    "transformer(garbo).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 1, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(model)\n",
    "imEncoder = model.ImageEncoder([1, 16, 32, 64, 128, 256, 512], kernel_size=3, stride=2)\n",
    "garbo = torch.randn([3, 128, 128])\n",
    "imEncoder(garbo).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 128, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24, 64, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(model)\n",
    "attConv = model.AttentionConv()\n",
    "garbo = torch.randn([1, 12, 128, 128])\n",
    "# attConv(garbo).shape\n",
    "# attConv(garbo).shape\n",
    "attConv(garbo).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 128, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(ae)\n",
    "encoder = ae.AE()\n",
    "garbo = torch.randn([12, 128, 128])\n",
    "encoder(garbo).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 128, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(model)\n",
    "decoder = model.ImageDecoder128()\n",
    "garbo = torch.randn([12, 512, 1, 1])\n",
    "decoder(garbo).shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bba7e75823fc7474598fdaa9856f2217ab6bebf37b5fa259dabfeda760a6edd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
